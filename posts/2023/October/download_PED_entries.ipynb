{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e976b7a2",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Download Protein Ensemble Database entries\"\n",
    "author: \"Quyen Vu\"\n",
    "date: \"2023-10-14\"\n",
    "draft: False\n",
    "categories: [IDP]\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614176da",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The Protein Ensemble Database (PED) is a freely accessible repository designed for the submission of structural collections, which include intrinsically disordered proteins (IDPs). PED contains manually curated records of structural collections measured through techniques such as nuclear magnetic resonance spectroscopy, small-angle X-ray scattering, and fluorescence resonance energy transfer. These structural coordinates can be utilized to assess these collections, thereby aiding the development of novel modeling approaches aimed at enhancing our ability to establish links between the inherent \"absence of a fixed structure\" in IDPs and their functions. Each PED entry corresponds to the primary experimental data and the structural collections associated with these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d7856",
   "metadata": {},
   "source": [
    "# Download Entry file as `tar.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<u><b> Note:</b></u> The following code works with the new version of PED. For the old version, please refer to this page:  [https://old.proteinensemble.org/help](https://old.proteinensemble.org/help){target=\"_blank\"}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "198b910f4e75f0f5"
  },
  {
   "cell_type": "markdown",
   "id": "0dbf823c",
   "metadata": {},
   "source": [
    "PED provides many ensembles of various proteins. We can write a simple code to automatically download `tar.gz` file then extract them for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060de98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# for extracting, moving and so on\n",
    "import tarfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6086c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_entry(PEDID):\n",
    "    \"\"\"\n",
    "    Download structural ensemble data for a given Protein Ensemble Database (PED) entry.\n",
    "\n",
    "    Parameters:\n",
    "    - PEDID (int): The unique identifier of the PED entry to download.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    This function fetches and downloads structural ensemble data for a specific PED entry\n",
    "    identified by its unique PEDID. It connects to the PED API to retrieve information\n",
    "    about the entry and its associated ensembles, then downloads the corresponding\n",
    "    structural data in the form of compressed tar.gz files.\n",
    "\n",
    "    Example Usage:\n",
    "    download_entry(123)  # Downloads structural ensemble data for PED entry 123.\n",
    "    \"\"\"\n",
    "    # Create the PED entry ID with leading zeros (e.g., PED00001)\n",
    "    ped_id = f\"PED{PEDID:05d}\"\n",
    "    \n",
    "    # Check and create the 'single' and 'multiple' folders if they don't exist\n",
    "    if not os.path.exists('single'):\n",
    "        os.makedirs('single')\n",
    "    if not os.path.exists('multiple'):\n",
    "        os.makedirs('multiple')\n",
    "\n",
    "    # Construct the URL for fetching PED entry information\n",
    "    url = \"https://deposition.proteinensemble.org/api/v1/entries/\" + ped_id\n",
    "\n",
    "    # Send a GET request to the PED API\n",
    "    res = requests.get(url)\n",
    "\n",
    "    # Check the response status code\n",
    "    if res.status_code == 200:\n",
    "        # Parse the response as JSON\n",
    "        res = res.json()\n",
    "\n",
    "        # Print the PED entry ID and its title/description\n",
    "        print(ped_id)\n",
    "        print(res['description'].get('title'))\n",
    "\n",
    "        # Determine the folder to save the downloaded files\n",
    "        n_constructs = len(res['construct_chains'])\n",
    "        if n_constructs == 1:\n",
    "            folder = 'single/'\n",
    "        else:\n",
    "            folder = 'multiple/'\n",
    "\n",
    "        # Extract ensemble IDs\n",
    "        ensembles_ids = [ensemble[\"ensemble_id\"] for ensemble in res[\"ensembles\"]]\n",
    "\n",
    "        # Print the ensemble IDs\n",
    "        print(ensembles_ids)\n",
    "\n",
    "        # Define the base download link template\n",
    "        download_link = \"https://deposition.proteinensemble.org/api/v1/entries/ENTRYID/ensembles/ENSID/ensemble-pdb?response_format=json&only_features=true\"\n",
    "\n",
    "        # Iterate through ensemble IDs and download each ensemble's data\n",
    "        for ensemble_id in ensembles_ids:\n",
    "            # Replace placeholders in the download link with actual PED and ensemble IDs\n",
    "            u = download_link.replace('ENTRYID', ped_id)\n",
    "            u = u.replace(\"ENSID\", ensemble_id)\n",
    "\n",
    "            # Download the ensemble data and save it as a tar.gz file\n",
    "            res_file = requests.get(u)\n",
    "            with open(f\"{folder}{ped_id}{ensemble_id}.tar.gz\", \"wb\") as f:\n",
    "                f.write(res_file.content)\n",
    "\n",
    "    elif res.status_code == 404:\n",
    "        # Handle the case where the PED entry does not exist\n",
    "        print(f\"{ped_id} does not exist in the database.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this function, we will download and handle two cases: 1) entry contains single chain `n_constructs = 1` and 2) entry contains multiple chains `n_constructs > 1` (which we will separate them later).\n",
    "\n",
    "Each type of entry will be saved in separate folder: `single` and `multiple` - we first check if folder exists, if not we will create them."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19e1e550549360c9"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f4f1702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PED00226\n",
      "N-terminal domain of dimeric eIF4G1 (1-249) from S. cerevisieae\n",
      "['e001']\n"
     ]
    }
   ],
   "source": [
    "# in case of missing something, can run download function one by one\n",
    "download_entry(226)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0654534e",
   "metadata": {},
   "source": [
    "# Extract TAR file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5239bab0",
   "metadata": {},
   "source": [
    "Now, extract tar file and change the filename, move to proper folders ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "400fd8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_move_files(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Extract and move files from tar.gz archives or a folder containing tar.gz archives.\n",
    "\n",
    "    Parameters:\n",
    "    - input_path (str): The path to the tar.gz file or folder containing tar.gz archives.\n",
    "    - output_path (str): The path where extracted files will be moved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    This function iterates through tar.gz files in the specified input path or folder, extracts their contents,\n",
    "    and moves the extracted files to the specified output path with appropriate naming.\n",
    "\n",
    "    Example Usage:\n",
    "    extract_and_move_files('input.tar.gz', 'output_folder/')\n",
    "    extract_and_move_files('archive_folder/', 'output_folder/')\n",
    "    \"\"\"\n",
    "    if os.path.isfile(input_path) and input_path.endswith(\".tar.gz\"):\n",
    "        # Handle the case where the input path is a tar.gz file\n",
    "        entry_ensemble_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "        with tarfile.open(input_path, 'r') as tf:\n",
    "            print(f\"Input tar file: {input_path}, pdb files in this archive file: {tf.getnames()}\")\n",
    "            # Extract all files\n",
    "            tf.extractall(path=output_path)\n",
    "            # Move extracted file to a filename of PED_ENTRY+.pdb\n",
    "            src = os.path.join(output_path, tf.getnames()[0])\n",
    "            dst = os.path.join(output_path, f'{entry_ensemble_name[:-4]}.pdb')\n",
    "            print(f\"source file: {src}, destination file: {dst}\")\n",
    "            shutil.move(src, dst)\n",
    "    elif os.path.isdir(input_path):\n",
    "        # Handle the case where the input path is a folder containing tar.gz files\n",
    "        for tar_file in os.listdir(input_path):\n",
    "            if tar_file.endswith(\".tar.gz\"):\n",
    "                entry_ensemble_name = tar_file.rsplit('.')[0]\n",
    "                with tarfile.open(os.path.join(input_path, tar_file), 'r') as tf:\n",
    "                    print(f\"Input tar file: {tar_file}, pdb files in this archive file: {tf.getnames()}\")\n",
    "                    # Extract all files\n",
    "                    tf.extractall(path=output_path)\n",
    "                    # Move extracted file to a filename of PED_ENTRY+.pdb\n",
    "                    src = os.path.join(output_path, tf.getnames()[0])\n",
    "                    dst = os.path.join(output_path, f'{entry_ensemble_name}.pdb')\n",
    "                    print(f\"source file: {src}, destination file: {dst}\")\n",
    "                    shutil.move(src, dst)\n",
    "    else:\n",
    "        print(\"Invalid input_path. Please provide a valid path to a tar.gz file or a folder containing tar.gz archives.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we use `shutil.move` function to rename ensemble because some entries has ensemble name in `tar.gz` and the actual ensemble name are different (e.g `PED00216` which `tar.gz` file is `e001` but pdb is named `e000`, many other entries have pdb file is just `pdbfile.pdb`). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81c85ff70693fcf"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c7d94f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tar file: PED00001e003.tar.gz, pdb files in this archive file: ['PED00001e003.pdb']\n",
      "source file: pdb_single/PED00001e003.pdb, destination file: pdb_single/PED00001e003.pdb\n",
      "Input tar file: PED00001e002.tar.gz, pdb files in this archive file: ['PED00001e002.pdb']\n",
      "source file: pdb_single/PED00001e002.pdb, destination file: pdb_single/PED00001e002.pdb\n",
      "Input tar file: PED00001e001.tar.gz, pdb files in this archive file: ['PED00001e001.pdb']\n",
      "source file: pdb_single/PED00001e001.pdb, destination file: pdb_single/PED00001e001.pdb\n"
     ]
    }
   ],
   "source": [
    "# Example Usage:\n",
    "extract_and_move_files('single', 'pdb_single/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43eb7316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tar file: single/PED00001e003.tar.gz, pdb files in this archive file: ['PED00001e003.pdb']\n",
      "pdb_single/PED00001e003.pdb pdb_single/PED00001e003.pdb\n"
     ]
    }
   ],
   "source": [
    "extract_and_move_files('single/PED00001e003.tar.gz', 'pdb_single/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c34674b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tar file: PED00226e001.tar.gz, pdb files in this archive file: ['PED00226e000.pdb']\n",
      "source file: pdb_multiple/PED00226e000.pdb, destination file: pdb_multiple/PED00226e001.pdb\n"
     ]
    }
   ],
   "source": [
    "extract_and_move_files('multiple', 'pdb_multiple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0fb6d7",
   "metadata": {},
   "source": [
    "## Separate chains and fix PDB if necessary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098fa1e",
   "metadata": {},
   "source": [
    "For the entry with multiple chains, before we can perform entanglement analysis, we need additional step is seperate individual chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b548b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_chains(original_pdb, output_folder):\n",
    "    \"\"\"\n",
    "    Separate chains from a Protein Data Bank (PDB) file and save them as individual files.\n",
    "\n",
    "    Parameters:\n",
    "    - original_pdb (str): The path to the original PDB file to process.\n",
    "    - output_folder (str): The folder where the separated chain files will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "\n",
    "    This function reads an original PDB file and separates its contents into individual chain-specific\n",
    "    PDB files. Each chain-specific file contains only the alpha carbon (CA) atom records for a particular chain.\n",
    "\n",
    "    If the specified output folder does not exist, it will be created.\n",
    "\n",
    "    Example Usage:\n",
    "    separate_chains(\"input.pdb\", \"output_folder/\")\n",
    "    \"\"\"\n",
    "    # Extract the base name without the file extension\n",
    "    base_name = os.path.splitext(os.path.basename(original_pdb))[0]\n",
    "\n",
    "    # Check if the output folder exists, and create it if it doesn't\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Read content of the original PDB file\n",
    "    with open(original_pdb, 'r') as f:\n",
    "        content = f.readlines()\n",
    "\n",
    "    # Collect unique chain identifiers and alternate location indicators\n",
    "    chain_identifiers = set()\n",
    "    alternate_location_indicators = set()\n",
    "\n",
    "    for line in content:\n",
    "        if line.startswith(\"ATOM\"):\n",
    "            chain_identifiers.add(line[21:22])\n",
    "            alternate_location_indicators.add(line[16:17])\n",
    "\n",
    "    # Create separate PDB files for each chain\n",
    "    for chain_identifier in chain_identifiers:\n",
    "        output_file = os.path.join(output_folder, f\"{base_name}_{chain_identifier}.pdb\")\n",
    "\n",
    "        with open(output_file, 'w') as f:\n",
    "            for line in content:\n",
    "                if line.startswith(\"MODEL\") or line.startswith(\"ENDMDL\"):\n",
    "                    # Write entire MODEL and ENDMDL lines\n",
    "                    f.write(line)\n",
    "                elif line.startswith(\"ATOM\"):\n",
    "                    atom_name = line[12:16].strip()\n",
    "                    current_chain = line[21:22]\n",
    "                    alternate_location = line[16:17]\n",
    "\n",
    "                    # Check if the line matches the criteria for the current chain\n",
    "                    if atom_name == \"CA\" and current_chain == chain_identifier and alternate_location in alternate_location_indicators:\n",
    "                        f.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2805975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate_chains('pdb_multiple/PED00226e001.pdb', 'fixed_multiple')\n",
    "# Example Usage:\n",
    "separate_chains('pdb_multiple/PED00226e001.pdb', \"output_folder/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d31b94",
   "metadata": {},
   "source": [
    "# Entanglement analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b058b",
   "metadata": {},
   "source": [
    "Now, time to run entanglement analysis. For multiple chains in entry, we need to seperate chains before run analysis but now, just go ahead with single chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee962b",
   "metadata": {},
   "source": [
    "This general command works:\n",
    "\n",
    "`julia -t 8 /home/qvv5013/work3/code/entanglement_analysis/gauss_linking.jl -f pdb_single/PED00216e001.pdb -o .`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d9d81",
   "metadata": {},
   "source": [
    "A more detailed of this analysis will be provided later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d5387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
